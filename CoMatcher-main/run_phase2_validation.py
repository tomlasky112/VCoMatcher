"""
VCoMatcher Phase 2: ä¸€é”®å®Œæ•´éªŒè¯è„šæœ¬
=====================================

è¿è¡Œæ‰€æœ‰ Phase 2 éªŒè¯æµ‹è¯•ï¼Œç”Ÿæˆå®Œæ•´æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
    python run_phase2_validation.py

é€‰é¡¹:
    --quick          åªè¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆè·³è¿‡æ€§èƒ½æµ‹è¯•å’Œå¯è§†åŒ–ï¼‰
    --full           è¿è¡Œå®Œæ•´æµ‹è¯•ï¼ˆåŒ…æ‹¬æ€§èƒ½å’Œå¯è§†åŒ–ï¼‰
    --benchmark      åªè¿è¡Œæ€§èƒ½æµ‹è¯•
    --visualize      åªè¿è¡Œå¯è§†åŒ–
"""

import sys
import time
import argparse
from pathlib import Path

# æ·»åŠ å¿…è¦çš„å¯¼å…¥
import numpy as np
import torch
from torch.utils.data import DataLoader

from vcomatcher_phase2_dataset import (
    VCoMatcherDataset,
    MixedDataLoader,
    collate_fn,
    compute_source_aware_weights,
)


def print_header(title):
    """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80 + "\n")


def run_sliding_window_tests():
    """è¿è¡Œæ»‘åŠ¨çª—å£OOMè§£å†³æ–¹æ¡ˆæµ‹è¯•"""
    print_header("Phase 1 æ»‘åŠ¨çª—å£æµ‹è¯• (OOM Solution)")
    
    try:
        from test_sliding_window import (
            test_umeyama_alignment_known_transform,
            test_umeyama_edge_cases,
            test_pose_points_synchronization,
            test_linear_blending,
            test_window_creation,
            test_sliding_window_end_to_end,
            test_memory_efficiency,
        )
    except ImportError as e:
        print(f"âš ï¸ æ— æ³•å¯¼å…¥ test_sliding_window.py")
        print(f"   é”™è¯¯è¯¦æƒ…: {e}")
        print("\nâ­ï¸  è·³è¿‡æ»‘åŠ¨çª—å£æµ‹è¯•...\n")
        return []
    except Exception as e:
        print(f"âŒ å¯¼å…¥æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        print("â­ï¸  è·³è¿‡æ»‘åŠ¨çª—å£æµ‹è¯•...\n")
        return []
    
    tests = [
        ("Umeyamaå·²çŸ¥å˜æ¢", test_umeyama_alignment_known_transform),
        ("Umeyamaè¾¹ç•Œæƒ…å†µ", test_umeyama_edge_cases),
        ("ä½å§¿-ç‚¹äº‘åŒæ­¥", test_pose_points_synchronization),
        ("çº¿æ€§å¹³æ»‘", test_linear_blending),
        ("çª—å£åˆ›å»º", test_window_creation),
        ("ç«¯åˆ°ç«¯å¤„ç†", test_sliding_window_end_to_end),
        ("å†…å­˜æ•ˆç‡", test_memory_efficiency),
    ]
    
    results = []
    for name, test_func in tests:
        print(f"\n{'â”€'*80}")
        print(f"è¿è¡Œæµ‹è¯•: {name}")
        print(f"{'â”€'*80}")
        
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
            results.append((name, False))
    
    return results


def run_basic_tests():
    """è¿è¡ŒåŸºç¡€å•å…ƒæµ‹è¯•"""
    print_header("Phase 2 åŸºç¡€æµ‹è¯•")
    
    # Try to import test functions
    try:
        from test_phase2_dataset import (
            test_target_centric_transformation,
            test_dataset_loading,
            test_dataloader,
            test_source_aware_weights,
            test_mixed_dataloader,
        )
    except ImportError as e:
        print(f"âš ï¸ æ— æ³•å¯¼å…¥ test_phase2_dataset.py")
        print(f"   é”™è¯¯è¯¦æƒ…: {e}")
        
        # Check if file exists
        from pathlib import Path
        if not Path("test_phase2_dataset.py").exists():
            print("   åŸå› : æ–‡ä»¶ä¸å­˜åœ¨")
        else:
            print("   åŸå› : å¯¼å…¥é”™è¯¯ï¼ˆå¯èƒ½ç¼ºå°‘ä¾èµ–æˆ–ä»£ç é”™è¯¯ï¼‰")
            print("   å»ºè®®: æ£€æŸ¥ test_phase2_dataset.py çš„è¯­æ³•å’Œä¾èµ–")
        
        print("\nâ­ï¸  è·³è¿‡åŸºç¡€æµ‹è¯•ï¼Œç»§ç»­è¯¦ç»†éªŒè¯...\n")
        return []
    except Exception as e:
        print(f"âŒ å¯¼å…¥æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        print("â­ï¸  è·³è¿‡åŸºç¡€æµ‹è¯•ï¼Œç»§ç»­è¯¦ç»†éªŒè¯...\n")
        return []
    
    # Try to import advanced tests (may not exist in older versions)
    try:
        from test_phase2_dataset import (
            test_multi_view_sampling,
            test_geometric_consistency,
            test_mask_boundary_conditions,
            test_curriculum_schedule_correctness,
        )
        advanced_tests_available = True
    except ImportError:
        advanced_tests_available = False
        print("  â„¹ï¸  é«˜çº§æµ‹è¯•æœªæ‰¾åˆ°ï¼Œä½¿ç”¨åŸºç¡€æµ‹è¯•")
    
    tests = [
        ("ç›®æ ‡ä¸­å¿ƒåŒ–å˜æ¢", test_target_centric_transformation),
        ("æ•°æ®é›†åŠ è½½", test_dataset_loading),
        ("DataLoader æ‰¹å¤„ç†", test_dataloader),
        ("ä¸ç¡®å®šæ€§æƒé‡", test_source_aware_weights),
        ("æ··åˆæ•°æ®åŠ è½½", test_mixed_dataloader),
    ]
    
    # Add advanced tests if available
    if advanced_tests_available:
        tests.extend([
            ("å¤šè§†å›¾é‡‡æ ·", test_multi_view_sampling),
            ("å‡ ä½•ä¸€è‡´æ€§", test_geometric_consistency),
            ("æ©è†œè¾¹ç•Œæ¡ä»¶", test_mask_boundary_conditions),
            ("è¯¾ç¨‹å­¦ä¹ è°ƒåº¦", test_curriculum_schedule_correctness),
        ])
    
    results = []
    for name, test_func in tests:
        print(f"\n{'â”€'*80}")
        print(f"è¿è¡Œæµ‹è¯•: {name}")
        print(f"{'â”€'*80}")
        
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
            results.append((name, False))
    
    return results


def run_detailed_verification():
    """è¿è¡Œè¯¦ç»†éªŒè¯"""
    print_header("Phase 2 è¯¦ç»†éªŒè¯")
    
    # æŸ¥æ‰¾æ•°æ® - FIXED: æœç´¢æ‰€æœ‰.npzæ–‡ä»¶ï¼Œä¸é™å®š_fixedåç¼€
    data_dir = Path("./data/vcomatcher_phase1_test")
    
    # BUGFIX: Check if directory exists first
    if not data_dir.exists():
        print(f"âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("   è¯·å…ˆè¿è¡Œ Phase 1 æ•°æ®ç”Ÿæˆ")
        return False
    
    data_paths = list(data_dir.glob("*.npz"))  # ä¿®å¤ï¼šä» *_fixed.npz æ”¹ä¸º *.npz
    
    if not data_paths:
        print("âš ï¸ æœªæ‰¾åˆ° Phase 1 æ•°æ®ï¼Œè·³è¿‡è¯¦ç»†éªŒè¯")
        return False
    
    try:
        dataset = VCoMatcherDataset(
            data_paths, 
            sample_types=["easy", "hard", "extreme"],
            cache_data=True
        )
        
        print(f"[1] æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(dataset)}")
        
        # æ ·æœ¬ç±»å‹ç»Ÿè®¡
        sample_types = {"easy": 0, "hard": 0, "extreme": 0}
        for sample in dataset.samples:
            sample_types[sample["sample_type"]] += 1
        
        total = len(dataset)
        # BUGFIX: Handle division by zero when dataset is empty
        if total > 0:
            print(f"  Easy:    {sample_types['easy']:6d} ({sample_types['easy']/total*100:5.1f}%)")
            print(f"  Hard:    {sample_types['hard']:6d} ({sample_types['hard']/total*100:5.1f}%)")
            print(f"  Extreme: {sample_types['extreme']:6d} ({sample_types['extreme']/total*100:5.1f}%)")
        else:
            print(f"  âš ï¸  æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ ·æœ¬")
        
        # åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬
        print(f"\n[2] éªŒè¯ç¬¬ä¸€ä¸ªæ ·æœ¬:")
        batch = dataset[0]
        
        # æ£€æŸ¥ Target ä½å§¿
        extrinsic_rel = batch["extrinsic_rel"]
        target_pose = extrinsic_rel[0]
        is_identity = torch.allclose(target_pose, torch.eye(4), atol=1e-4)
        
        print(f"  Target æ˜¯ Identity: {'âœ“' if is_identity else 'âœ—'}")
        
        if not is_identity:
            error = torch.abs(target_pose - torch.eye(4)).max().item()
            print(f"  è¯¯å·®: {error:.6f}")
        
        # æ£€æŸ¥æ©è†œè¦†ç›–ç‡
        print(f"\n[3] æ©è†œè¦†ç›–ç‡:")
        mask_geom = batch["mask_geom"]
        mask_loss = batch["mask_loss"]
        
        geom_ratio = mask_geom.float().mean().item() * 100
        loss_ratio = mask_loss.float().mean().item() * 100
        
        print(f"  mask_geom: {geom_ratio:.1f}%")
        print(f"  mask_loss: {loss_ratio:.1f}%")
        
        # åˆ¤æ–­æ˜¯å¦åˆæ ¼ (v1.6 updated: 60-75% is ideal)
        loss_ok = 60 <= loss_ratio <= 75
        print(f"  çŠ¶æ€: {'âœ“ åˆæ ¼' if loss_ok else 'âš ï¸ éœ€è¦è°ƒæ•´'}")
        
        # BUGFIX: Provide guidance if out of range
        if not loss_ok:
            if loss_ratio < 60:
                print(f"    å»ºè®®: mask_losså¤ªä½ï¼Œè€ƒè™‘å¢åŠ  --tau_uncertainty")
            else:
                print(f"    å»ºè®®: mask_losså¤ªé«˜ï¼Œè€ƒè™‘å‡å° --tau_uncertainty")
        
        # æ£€æŸ¥ç‚¹äº‘
        print(f"\n[4] ç‚¹äº‘æ£€æŸ¥:")
        points_3d = batch["points_3d"]
        target_points = points_3d[0]
        target_depth = target_points[..., 2]
        
        positive_ratio = (target_depth > 0).float().mean().item() * 100
        print(f"  æ­£æ·±åº¦æ¯”ä¾‹: {positive_ratio:.1f}%")
        print(f"  æ·±åº¦èŒƒå›´: [{target_depth.min():.2f}, {target_depth.max():.2f}]")
        
        print(f"\nâœ“ è¯¦ç»†éªŒè¯å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âœ— è¯¦ç»†éªŒè¯å¤±è´¥: {e}")
        return False


def run_performance_benchmark():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print_header("Phase 2 æ€§èƒ½æµ‹è¯•")
    
    data_dir = Path("./data/vcomatcher_phase1_test")
    
    # BUGFIX: Check directory exists
    if not data_dir.exists():
        print(f"âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
    
    data_paths = list(data_dir.glob("*.npz"))  # FIXED: ä» *_fixed.npz æ”¹ä¸º *.npz
    
    if not data_paths:
        print("âš ï¸ æœªæ‰¾åˆ°æ•°æ®ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
        return False
    
    try:
        # æµ‹è¯• 1: æ— ç¼“å­˜ (å•è¿›ç¨‹)
        print(f"[1] å†·å¯åŠ¨æµ‹è¯• (cache=False, workers=0):") 
        dataset_nocache = VCoMatcherDataset(data_paths, cache_data=False)
        
        start = time.time()
        for i in range(10):
            _ = dataset_nocache[i]
        elapsed = time.time() - start
        
        speed_nocache = 10 / elapsed
        print(f"  é€Ÿåº¦: {speed_nocache:.1f} samples/sec")
        
        # æµ‹è¯• 2: æœ‰ç¼“å­˜ (å•è¿›ç¨‹)
        print(f"\n[2] çƒ­å¯åŠ¨æµ‹è¯• (cache=True, workers=0):")
        dataset_cache = VCoMatcherDataset(data_paths, cache_data=True)
        
        # é¢„çƒ­
        for i in range(10):
            _ = dataset_cache[i]
        
        start = time.time()
        for i in range(100):
            _ = dataset_cache[i % 10]
        elapsed = time.time() - start
        
        speed_cache = 100 / elapsed
        print(f"  é€Ÿåº¦: {speed_cache:.1f} samples/sec")
        print(f"  åŠ é€Ÿæ¯”: {speed_cache/speed_nocache:.1f}x")
        
        # æµ‹è¯• 3: DataLoader å•è¿›ç¨‹
        print(f"\n[3] DataLoader ååé‡ (cache=True, workers=0):")
        dataloader = DataLoader(
            dataset_cache,
            batch_size=8,
            num_workers=0,
            shuffle=False,
            collate_fn=collate_fn,
        )
        
        start = time.time()
        for batch in dataloader:
            pass
        elapsed = time.time() - start
        
        total_samples = len(dataset_cache)
        # BUGFIX: Handle zero elapsed time (very fast execution)
        if elapsed > 0:
            throughput = total_samples / elapsed
            print(f"  ååé‡: {throughput:.1f} samples/sec")
        else:
            print(f"  ååé‡: Too fast to measure (< 1ms)")
        
        # æµ‹è¯• 4: çœŸå®è®­ç»ƒåœºæ™¯ (æ— ç¼“å­˜ + å¤šè¿›ç¨‹) â­
        print(f"\n[4] â­ çœŸå®è®­ç»ƒåœºæ™¯ (cache=False, workers=4):")
        print(f"  (å¤§æ•°æ®é›†å¦‚ScanNet/MegaDepthçš„å…¸å‹é…ç½®)")
        
        dataset_real = VCoMatcherDataset(data_paths, cache_data=False)
        dataloader_real = DataLoader(
            dataset_real,
            batch_size=8,
            num_workers=4,
            shuffle=False,
            collate_fn=collate_fn,
            pin_memory=True,
            prefetch_factor=2,
        )
        
        #Warmup
        print(f"  é¢„çƒ­ä¸­...")
        for i, batch in enumerate(dataloader_real):
            if i >= 3:
                break
        
        # Benchmark
        start = time.time()
        for batch in dataloader_real:
            pass
        elapsed = time.time() - start
        
        # BUGFIX: Handle zero elapsed time
        if elapsed > 0:
            throughput_real = total_samples / elapsed
            print(f"  ååé‡: {throughput_real:.1f} samples/sec")
            print(f"  é¢„ä¼°è®­ç»ƒæ—¶é—´ (1 epoch = 1000 samples): {1000/throughput_real:.1f} ç§’")
        else:
            print(f"  ååé‡: Too fast to measure")
        
        print(f"\nâœ“ æ€§èƒ½æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âœ— æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def generate_visualizations():
    """ç”Ÿæˆå¯è§†åŒ–"""
    print_header("Phase 2 å¯è§†åŒ–ç”Ÿæˆ")
    
    try:
        import matplotlib
        matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
        import matplotlib.pyplot as plt
    except ImportError:
        print("âš ï¸ matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        return False
    
    data_dir = Path("./data/vcomatcher_phase1_test")
    
    # BUGFIX: Check directory exists and use correct glob pattern
    if not data_dir.exists():
        print(f"âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
    
    data_paths = list(data_dir.glob("*.npz"))  # FIXED: ä» *_fixed.npz æ”¹ä¸º *.npz
    
    if not data_paths:
        print("âš ï¸ æœªæ‰¾åˆ°æ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–")
        return False
    
    try:
        dataset = VCoMatcherDataset(data_paths, sample_types=["easy"])
        batch = dataset[0]
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        vis_dir = Path("visualizations/phase2")
        vis_dir.mkdir(parents=True, exist_ok=True)
        
        # å¯è§†åŒ– 1: ä½å§¿çŸ©é˜µ
        print(f"[1] ç”Ÿæˆä½å§¿çŸ©é˜µå¯è§†åŒ–...")
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle("Target-Centric Transformation", fontsize=14)
        
        extrinsic_rel = batch["extrinsic_rel"].numpy()
        
        for i, ax in enumerate(axes.flat):
            pose = extrinsic_rel[i]
            im = ax.imshow(pose, cmap='RdBu', vmin=-1, vmax=1)
            ax.set_title(f"View {i} {'(Target)' if i==0 else ''}")
            
            # æ·»åŠ æ•°å€¼
            for (j, k), val in np.ndenumerate(pose):
                color = 'white' if abs(val) > 0.5 else 'black'
                ax.text(k, j, f'{val:.2f}', 
                       ha='center', va='center', color=color, fontsize=8)
            
            plt.colorbar(im, ax=ax)
        
        plt.tight_layout()
        output_path = vis_dir / "target_centric_poses.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"  âœ“ ä¿å­˜åˆ°: {output_path}")
        
        # å¯è§†åŒ– 2: æ©è†œå¯¹æ¯”
        print(f"[2] ç”Ÿæˆæ©è†œå¯¹æ¯”å¯è§†åŒ–...")
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle("Dual Mask Comparison (View 0)", fontsize=14)
        
        mask_geom = batch["mask_geom"][0].numpy()
        mask_loss = batch["mask_loss"][0].numpy()
        depth = batch["depth"][0].numpy()
        uncertainty = batch["uncertainty_map"][0].numpy()
        
        im0 = axes[0, 0].imshow(depth, cmap='viridis')
        axes[0, 0].set_title("Depth Map")
        plt.colorbar(im0, ax=axes[0, 0])
        
        axes[0, 1].imshow(mask_geom, cmap='gray')
        axes[0, 1].set_title(f"mask_geom ({mask_geom.mean()*100:.1f}%)")
        
        axes[1, 0].imshow(mask_loss, cmap='gray')
        axes[1, 0].set_title(f"mask_loss ({mask_loss.mean()*100:.1f}%)")
        
        im1 = axes[1, 1].imshow(uncertainty, cmap='hot')
        axes[1, 1].set_title("Uncertainty Map")
        plt.colorbar(im1, ax=axes[1, 1])
        
        plt.tight_layout()
        output_path = vis_dir / "mask_comparison.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"  âœ“ ä¿å­˜åˆ°: {output_path}")
        
        print(f"\nâœ“ å¯è§†åŒ–ç”Ÿæˆå®Œæˆ")
        print(f"  æŸ¥çœ‹ç›®å½•: {vis_dir}")
        return True
        
    except Exception as e:
        print(f"âœ— å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def print_summary(basic_results, detailed_ok, perf_ok, vis_ok, sliding_window_results=None):
    """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
    print_header("éªŒè¯æ€»ç»“æŠ¥å‘Š")
    
    # Sliding window tests (if run)
    if sliding_window_results:
        print(f"[0] æ»‘åŠ¨çª—å£æµ‹è¯• (OOM Solution):")
        sw_passed = sum(1 for _, result in sliding_window_results if result)
        sw_total = len(sliding_window_results)
        
        for name, result in sliding_window_results:
            status = "âœ“ PASS" if result else "âœ— FAIL"
            print(f"  {name:25s}: {status}")
        
        if sw_total > 0:
            print(f"\n  é€šè¿‡ç‡: {sw_passed}/{sw_total} ({sw_passed/sw_total*100:.0f}%)")
        else:
            print(f"\n  é€šè¿‡ç‡: 0/0 (æ— æµ‹è¯•)")
        print()
    
    print(f"[1] åŸºç¡€æµ‹è¯•:")
    passed = sum(1 for _, result in basic_results if result)
    total = len(basic_results)
    
    for name, result in basic_results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"  {name:25s}: {status}")
    
    # BUGFIX: Handle division by zero when total is 0
    if total > 0:
        print(f"\n  é€šè¿‡ç‡: {passed}/{total} ({passed/total*100:.0f}%)")
    else:
        print(f"\n  é€šè¿‡ç‡: 0/0 (æ— æµ‹è¯•)")
    
    print(f"\n[2] è¯¦ç»†éªŒè¯: {'âœ“ PASS' if detailed_ok else 'âœ— FAIL / SKIP'}")
    print(f"[3] æ€§èƒ½æµ‹è¯•: {'âœ“ PASS' if perf_ok else 'âœ— FAIL / SKIP'}")
    print(f"[4] å¯è§†åŒ–ç”Ÿæˆ: {'âœ“ PASS' if vis_ok else 'âœ— FAIL / SKIP'}")
    
    # æ€»ä½“åˆ¤æ–­
    print(f"\n{'='*80}")
    if passed == total and detailed_ok:
        print("ğŸ‰ æ­å–œï¼Phase 2 æ•°æ®åŠ è½½å™¨å®Œå…¨å°±ç»ªï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. æŸ¥çœ‹ MD/PHASE3_STATUS_AND_TODO.md")
        print("  2. å¼€å§‹ Phase 3 å¼€å‘")
        print("  3. è¿è¡Œ: python vcomatcher_train.py (å¾…åˆ›å»º)")
    elif total > 0 and passed >= total * 0.8:
        print("âš ï¸ Phase 2 åŸºæœ¬å¯ç”¨ï¼Œä½†æœ‰éƒ¨åˆ†é—®é¢˜")
        print("\nå»ºè®®:")
        print("  1. æŸ¥çœ‹å¤±è´¥çš„æµ‹è¯•")
        print("  2. å‚è€ƒ MD/PHASE2_EXPERIMENT_GUIDE.md")
        print("  3. è§£å†³é—®é¢˜åé‡æ–°è¿è¡Œ")
    else:
        print("âœ— Phase 2 å­˜åœ¨ä¸¥é‡é—®é¢˜")
        print("\néœ€è¦:")
        print("  1. æ£€æŸ¥ Phase 1 æ•°æ®è´¨é‡")
        print("  2. æŸ¥çœ‹ MD/TROUBLESHOOTING.md")
        print("  3. é‡æ–°ç”Ÿæˆæ•°æ®æˆ–ä¿®å¤ä»£ç ")
    print("="*80 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description="VCoMatcher Phase 2 å®Œæ•´éªŒè¯"
    )
    parser.add_argument(
        "--quick",
        action="store_true",
        help="å¿«é€Ÿæ¨¡å¼ï¼ˆè·³è¿‡æ€§èƒ½å’Œå¯è§†åŒ–ï¼‰"
    )
    parser.add_argument(
        "--full",
        action="store_true",
        help="å®Œæ•´æ¨¡å¼ï¼ˆè¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼‰"
    )
    parser.add_argument(
        "--benchmark",
        action="store_true",
        help="åªè¿è¡Œæ€§èƒ½æµ‹è¯•"
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="åªè¿è¡Œå¯è§†åŒ–"
    )
    parser.add_argument(
        "--sliding-window",
        action="store_true",
        help="åªè¿è¡Œæ»‘åŠ¨çª—å£æµ‹è¯•"
    )
    
    args = parser.parse_args()
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print("\n" + "="*80)
    print("  VCoMatcher Phase 2 - å®Œæ•´éªŒè¯")
    print("="*80)
    print(f"\nå¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    start_time = time.time()
    
    # æ ¹æ®å‚æ•°è¿è¡Œæµ‹è¯•
    if args.sliding_window:
        sw_results = run_sliding_window_tests()
        sw_passed = sum(1 for _, result in sw_results if result)
        sw_total = len(sw_results)
        print(f"\næ€»è€—æ—¶: {time.time() - start_time:.1f} ç§’")
        print(f"\næ»‘åŠ¨çª—å£æµ‹è¯•: {sw_passed}/{sw_total} é€šè¿‡")
        sys.exit(0 if sw_passed == sw_total else 1)
    
    if args.benchmark:
        perf_ok = run_performance_benchmark()
        print(f"\næ€»è€—æ—¶: {time.time() - start_time:.1f} ç§’")
        sys.exit(0 if perf_ok else 1)
    
    if args.visualize:
        vis_ok = generate_visualizations()
        print(f"\næ€»è€—æ—¶: {time.time() - start_time:.1f} ç§’")
        sys.exit(0 if vis_ok else 1)
    
    # é»˜è®¤è¿è¡Œæµ‹è¯•
    # 1. Sliding window tests (Phase 1 OOM solution)
    sliding_window_results = run_sliding_window_tests()
    
    # 2. Basic Phase 2 tests
    basic_results = run_basic_tests()
    detailed_ok = run_detailed_verification()
    
    # æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦è¿è¡Œé¢å¤–æµ‹è¯•
    perf_ok = False
    vis_ok = False
    
    if args.full or not args.quick:
        perf_ok = run_performance_benchmark()
        vis_ok = generate_visualizations()
    
    # æ‰“å°æ€»ç»“
    elapsed = time.time() - start_time
    print(f"\næ€»è€—æ—¶: {elapsed:.1f} ç§’")
    
    print_summary(basic_results, detailed_ok, perf_ok, vis_ok, sliding_window_results)
    
    # è¿”å›é€€å‡ºç 
    basic_passed = sum(1 for _, result in basic_results if result)
    basic_total = len(basic_results)
    
    # Check sliding window results if they were run
    sw_passed = sum(1 for _, result in sliding_window_results if result) if sliding_window_results else 0
    sw_total = len(sliding_window_results) if sliding_window_results else 0
    
    # Consider sliding window tests in success criteria only if they were actually run
    if sw_total > 0:
        all_passed = (basic_passed == basic_total) and (sw_passed == sw_total) and detailed_ok
    else:
        all_passed = (basic_passed == basic_total) and detailed_ok
    
    if all_passed:
        sys.exit(0)  # æˆåŠŸ
    else:
        sys.exit(1)  # å¤±è´¥


if __name__ == "__main__":
    main()

